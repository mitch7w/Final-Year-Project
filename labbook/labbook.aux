\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\AC@reset@newl@bel
\babel@aux{british}{}
\citation{Du2Net}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}2022 March}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/03/30}{5}{section*.3}\protected@file@percent }
\newlabel{sec:20220330}{{1}{5}{2022/03/30}{section*.3}{}}
\@writefile{toc}{\contentsline {subsection}{Background reading and research}{5}{subsection*.4}\protected@file@percent }
\@writefile{brf}{\backcite{Du2Net}{{5}{1}{subsection*.4}}}
\citation{hand_ar_shen}
\citation{hand_ar_shen}
\citation{canterbury_hand_ar}
\@writefile{toc}{\contentsline {section}{2022/03/31}{7}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Prototype ideas}{7}{subsection*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Literature Analysis}{7}{subsection*.7}\protected@file@percent }
\@writefile{brf}{\backcite{hand_ar_shen}{{7}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{hand_ar_shen}{{7}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{canterbury_hand_ar}{{7}{1}{subsection*.7}}}
\citation{kim_leap_ar}
\citation{lee_hand_ar}
\citation{jones_skin_color}
\citation{drones_hololens}
\citation{mediapipe_hands}
\citation{hand_ar_shen}
\@writefile{brf}{\backcite{kim_leap_ar}{{8}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{lee_hand_ar}{{8}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{jones_skin_color}{{8}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{drones_hololens}{{8}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{mediapipe_hands}{{8}{1}{subsection*.7}}}
\@writefile{brf}{\backcite{hand_ar_shen}{{8}{1}{subsection*.7}}}
\@writefile{toc}{\contentsline {subsection}{Impact on system to be developed}{8}{subsection*.8}\protected@file@percent }
\citation{mediapipe_hands}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}2022 April}{10}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/04/01}{10}{section*.9}\protected@file@percent }
\newlabel{sec:20220401}{{2}{10}{2022/04/01}{section*.9}{}}
\@writefile{toc}{\contentsline {subsection}{Initial prototypes}{10}{subsection*.10}\protected@file@percent }
\@writefile{brf}{\backcite{mediapipe_hands}{{10}{2}{subsection*.10}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Open-hand input to TeachableMachine gesture recognition prototype\relax }}{11}{figure.caption.11}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:teachablemachine1}{{2.1}{11}{Open-hand input to TeachableMachine gesture recognition prototype\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Closed-hand input to TeachableMachine gesture recognition prototype\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:teachablemachine2}{{2.2}{11}{Closed-hand input to TeachableMachine gesture recognition prototype\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Cube rendering prototype output\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:room_cube}{{2.3}{12}{Cube rendering prototype output\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{2022/04/03}{13}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Functional block diagram updates}{13}{subsection*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces FBD draft 2\relax }}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:fbd_draft2}{{2.4}{13}{FBD draft 2\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{Initial hardware prototypes}{13}{subsection*.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The ultrasonic sensor connected to an Arduino Uno\relax }}{14}{figure.caption.18}\protected@file@percent }
\newlabel{fig:ultrasonic_setup}{{2.5}{14}{The ultrasonic sensor connected to an Arduino Uno\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The ultrasonic sensor measuring test\relax }}{14}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ultrasonic_measuring}{{2.6}{14}{The ultrasonic sensor measuring test\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Graph of measuring experiment using HC-SR04\relax }}{14}{figure.caption.20}\protected@file@percent }
\newlabel{fig:HCSR04_graph}{{2.7}{14}{Graph of measuring experiment using HC-SR04\relax }{figure.caption.20}{}}
\citation{mediapipe_hands}
\@writefile{toc}{\contentsline {section}{2022/04/04}{16}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Project proposal improvements}{16}{subsection*.22}\protected@file@percent }
\@writefile{brf}{\backcite{mediapipe_hands}{{16}{2}{subsection*.22}}}
\@writefile{toc}{\contentsline {section}{2022/04/05}{17}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Embedded neural network prototype}{17}{subsection*.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Output of the ESP32 web server running the hand gesture model\relax }}{17}{figure.caption.25}\protected@file@percent }
\newlabel{fig:esp32_cam1}{{2.8}{17}{Output of the ESP32 web server running the hand gesture model\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Output of the ESP32 web server running the hand gesture model\relax }}{18}{figure.caption.26}\protected@file@percent }
\newlabel{fig:esp32_cam2}{{2.9}{18}{Output of the ESP32 web server running the hand gesture model\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{2022/04/14}{19}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Libfreenect demonstration program}{19}{subsection*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/04/15}{20}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Libfreenect testing}{20}{subsection*.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Output of the libfreenect demo program\relax }}{20}{figure.caption.31}\protected@file@percent }
\newlabel{fig:kinect_demo}{{2.10}{20}{Output of the libfreenect demo program\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{2022/04/20}{21}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Initial Version Of Experimental Plan}{21}{subsection*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/04/30}{23}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Image thresholding prototypes}{23}{subsection*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Webcam input to the red thresholder algorithm\relax }}{23}{figure.caption.36}\protected@file@percent }
\newlabel{fig:red_thresholder_original}{{2.11}{23}{Webcam input to the red thresholder algorithm\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Output of the red thresholder algorithm\relax }}{24}{figure.caption.37}\protected@file@percent }
\newlabel{fig:red_thresholder_test}{{2.12}{24}{Output of the red thresholder algorithm\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Binary threshold algorithm\relax }}{24}{figure.caption.38}\protected@file@percent }
\newlabel{fig:threshold_binary}{{2.13}{24}{Binary threshold algorithm\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Inverse Binary threshold algorithm\relax }}{24}{figure.caption.39}\protected@file@percent }
\newlabel{fig:threshold_binary_inverse}{{2.14}{24}{Inverse Binary threshold algorithm\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Trucated threshold algorithm\relax }}{24}{figure.caption.40}\protected@file@percent }
\newlabel{fig:threshold_truncated}{{2.15}{24}{Trucated threshold algorithm\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Truncated Zero threshold algorithm\relax }}{25}{figure.caption.41}\protected@file@percent }
\newlabel{fig:threshold_zero}{{2.16}{25}{Truncated Zero threshold algorithm\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Inverse Truncated Zero threshold algorithm\relax }}{25}{figure.caption.42}\protected@file@percent }
\newlabel{fig:threshold_zero_inverse}{{2.17}{25}{Inverse Truncated Zero threshold algorithm\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}2022 May}{26}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/05/07}{26}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Libfreenect library installation}{26}{subsection*.44}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Successful output of importing the libfreenect library\relax }}{27}{figure.caption.45}\protected@file@percent }
\newlabel{fig:libfreenect_success}{{3.1}{27}{Successful output of importing the libfreenect library\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {section}{2022/05/07}{28}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Virtual object control prototype using gesture input}{28}{subsection*.47}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Local mediapipe hand model prototype\relax }}{28}{figure.caption.48}\protected@file@percent }
\newlabel{fig:mediapipe_app}{{3.2}{28}{Local mediapipe hand model prototype\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Output of mediapipe hand model prototype\relax }}{29}{figure.caption.49}\protected@file@percent }
\newlabel{fig:mediapipe_prototype_output}{{3.3}{29}{Output of mediapipe hand model prototype\relax }{figure.caption.49}{}}
\citation{deep_pose}
\@writefile{toc}{\contentsline {section}{2022/05/09}{30}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Joint regression research}{30}{subsection*.51}\protected@file@percent }
\@writefile{brf}{\backcite{deep_pose}{{30}{3}{subsection*.51}}}
\citation{deep_pose}
\citation{mediapipe_hands}
\@writefile{toc}{\contentsline {section}{2022/05/16}{31}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Webcam resolution prototype}{31}{subsection*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Neural network prototype}{31}{subsection*.54}\protected@file@percent }
\@writefile{brf}{\backcite{deep_pose}{{31}{3}{subsection*.54}}}
\@writefile{brf}{\backcite{mediapipe_hands}{{31}{3}{subsection*.54}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces NN training data distribution\relax }}{32}{figure.caption.55}\protected@file@percent }
\newlabel{fig:NN_input_graph}{{3.4}{32}{NN training data distribution\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces NN prototype loss curve over 600 training epochs\relax }}{33}{figure.caption.56}\protected@file@percent }
\newlabel{fig:NN_prototype_600_epochs}{{3.5}{33}{NN prototype loss curve over 600 training epochs\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces NN prototype loss curve over 10000 training epochs\relax }}{33}{figure.caption.57}\protected@file@percent }
\newlabel{fig:NN_prototype_10000_epochs}{{3.6}{33}{NN prototype loss curve over 10000 training epochs\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces NN prototype training output over 600 training epochs with learning rate of 0.1\relax }}{34}{figure.caption.58}\protected@file@percent }
\newlabel{fig:NN_prototype_lrate_0.1_600_epochs}{{3.7}{34}{NN prototype training output over 600 training epochs with learning rate of 0.1\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces NN prototype training output end over 600 training epochs with learning rate of 0.1\relax }}{34}{figure.caption.59}\protected@file@percent }
\newlabel{fig:NN_prototype_lrate_0.1_600_epochs_end}{{3.8}{34}{NN prototype training output end over 600 training epochs with learning rate of 0.1\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces NN output of overfitting test on small input dataset\relax }}{34}{figure.caption.60}\protected@file@percent }
\newlabel{fig:NN_prototype_overfitting_test}{{3.9}{34}{NN output of overfitting test on small input dataset\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {section}{2022/05/17}{35}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Kernel Functions Experimentation}{35}{subsection*.62}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Input image to various kernel functions\relax }}{35}{figure.caption.63}\protected@file@percent }
\newlabel{fig:kernel_identity}{{3.10}{35}{Input image to various kernel functions\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Output of the edge detection 1 kernel function\relax }}{36}{figure.caption.64}\protected@file@percent }
\newlabel{fig:kernel_edge_detection_1}{{3.11}{36}{Output of the edge detection 1 kernel function\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Output of the edge detection 2 kernel function\relax }}{36}{figure.caption.65}\protected@file@percent }
\newlabel{fig:kernel_edge_detection_2}{{3.12}{36}{Output of the edge detection 2 kernel function\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Output of the left sobel kernel function\relax }}{37}{figure.caption.66}\protected@file@percent }
\newlabel{fig:kernel_left_sobel}{{3.13}{37}{Output of the left sobel kernel function\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Output of the right sobel kernel function\relax }}{37}{figure.caption.67}\protected@file@percent }
\newlabel{fig:kernel_right_sobel}{{3.14}{37}{Output of the right sobel kernel function\relax }{figure.caption.67}{}}
\@writefile{toc}{\contentsline {section}{2022/05/31}{38}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{OpenGL Cube Experimentation}{38}{subsection*.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Output of the OpenGL cube rendering program\relax }}{38}{figure.caption.70}\protected@file@percent }
\newlabel{fig:OpenGL_cube}{{3.15}{38}{Output of the OpenGL cube rendering program\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Output of the OpenGL cube rendering program overlaid on a video input feed\relax }}{39}{figure.caption.71}\protected@file@percent }
\newlabel{fig:OpenGL_cube1.png}{{3.16}{39}{Output of the OpenGL cube rendering program overlaid on a video input feed\relax }{figure.caption.71}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}2022 June}{40}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/06/06}{40}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Further OpenGL Prototyping}{40}{subsection*.73}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Output of the OpenGL and Mediapipe hands prototype application\relax }}{41}{figure.caption.74}\protected@file@percent }
\newlabel{fig:OpenGL Mediapipe Cube}{{4.1}{41}{Output of the OpenGL and Mediapipe hands prototype application\relax }{figure.caption.74}{}}
\@writefile{toc}{\contentsline {section}{2022/06/07}{42}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{OpenGL And Mediapipe Prototyping}{42}{subsection*.76}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Output of the Mediapipe hands python example application\relax }}{42}{figure.caption.77}\protected@file@percent }
\newlabel{fig:python_mediapipe_hands}{{4.2}{42}{Output of the Mediapipe hands python example application\relax }{figure.caption.77}{}}
\@writefile{toc}{\contentsline {section}{2022/06/17}{44}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Project Proposal Revision}{44}{subsection*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}2022 July}{46}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/07/06}{46}{section*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Convolution and max pooling algorithms}{46}{subsection*.81}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Proposed logic for convolution algorithm\relax }}{47}{figure.caption.82}\protected@file@percent }
\newlabel{fig:conv_alg_labbook}{{5.1}{47}{Proposed logic for convolution algorithm\relax }{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Calculations and logic for convolution algorithm\relax }}{48}{figure.caption.83}\protected@file@percent }
\newlabel{fig:conv_maths_labbook}{{5.2}{48}{Calculations and logic for convolution algorithm\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {section}{2022/07/07}{49}{section*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{CNN backpropogation for convolutional layers}{49}{subsection*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/07/08}{50}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Basic CNN testing}{50}{subsection*.87}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/07/12}{51}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Troubleshooting exploding weights and saturating neurons}{51}{subsection*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/07/13}{52}{section*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Output debugging in a textfile}{52}{subsection*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/07/14}{53}{section*.92}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{MNIST hand-written digit classifier}{53}{subsection*.93}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces First five output results of the MNIST classifier\relax }}{53}{figure.caption.94}\protected@file@percent }
\newlabel{fig:mnist_first_5_results}{{5.3}{53}{First five output results of the MNIST classifier\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {section}{2022/07/16}{54}{section*.95}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Single hand coordinate classifier}{54}{subsection*.96}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Proposed architecture for hand coordinate convolutional neural network\relax }}{54}{figure.caption.97}\protected@file@percent }
\newlabel{fig:hand_conv_arch_labbook}{{5.4}{54}{Proposed architecture for hand coordinate convolutional neural network\relax }{figure.caption.97}{}}
\@writefile{toc}{\contentsline {section}{2022/07/19}{56}{section*.98}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Gesture classifier}{56}{subsection*.99}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Loss curve of the gesture recognition neural network\relax }}{56}{figure.caption.100}\protected@file@percent }
\newlabel{fig:gesture_recognizer_loss_curve}{{5.5}{56}{Loss curve of the gesture recognition neural network\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Predicted gesture using gesture recognition neural network\relax }}{57}{figure.caption.101}\protected@file@percent }
\newlabel{fig:predictedGesture_rockon.png}{{5.6}{57}{Predicted gesture using gesture recognition neural network\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Predicted gesture using gesture recognition neural network\relax }}{57}{figure.caption.102}\protected@file@percent }
\newlabel{fig:predictedGesture_one}{{5.7}{57}{Predicted gesture using gesture recognition neural network\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Predicted gesture using gesture recognition neural network\relax }}{57}{figure.caption.103}\protected@file@percent }
\newlabel{fig:predictedGesture_peace}{{5.8}{57}{Predicted gesture using gesture recognition neural network\relax }{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Predicted gesture using gesture recognition neural network\relax }}{58}{figure.caption.104}\protected@file@percent }
\newlabel{fig:predictedGesture_ok}{{5.9}{58}{Predicted gesture using gesture recognition neural network\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {section}{2022/07/25}{59}{section*.105}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Kinect camera edge detection}{59}{subsection*.106}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Output of convolution of Kinect imagery with modified edge detection filter\relax }}{59}{figure.caption.107}\protected@file@percent }
\newlabel{fig:kinect_filter_edges}{{5.10}{59}{Output of convolution of Kinect imagery with modified edge detection filter\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces JET colormap interpretation of Kinect depth data\relax }}{60}{figure.caption.108}\protected@file@percent }
\newlabel{fig:kinect_colormap}{{5.11}{60}{JET colormap interpretation of Kinect depth data\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {section}{2022/07/26}{61}{section*.109}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Neural network refactoring }{61}{subsection*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}2022 August}{62}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/08/01}{62}{section*.111}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{First draft of literature review for first-semester report.}{62}{subsection*.112}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{OpenGL Movement API}{63}{subsection*.113}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces OpenGL virtual object at world coordinates 0,0.\relax }}{64}{figure.caption.114}\protected@file@percent }
\newlabel{fig:opengl_cube_coordinate_system}{{6.1}{64}{OpenGL virtual object at world coordinates 0,0.\relax }{figure.caption.114}{}}
\@writefile{toc}{\contentsline {section}{2022/08/02}{65}{section*.115}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Neural network convolutional layers}{65}{subsection*.116}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/08/03}{66}{section*.117}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{More training data for gesture classifier}{66}{subsection*.118}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/08/04}{67}{section*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Kinect Segmenting Prototyping And Keras Gesture learning}{67}{subsection*.120}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Segmenting an image based on the Kinect depth data\relax }}{67}{figure.caption.121}\protected@file@percent }
\newlabel{fig:kinect_segment1}{{6.2}{67}{Segmenting an image based on the Kinect depth data\relax }{figure.caption.121}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Segmenting an image based on the Kinect depth data\relax }}{68}{figure.caption.122}\protected@file@percent }
\newlabel{fig:kinect_segment2}{{6.3}{68}{Segmenting an image based on the Kinect depth data\relax }{figure.caption.122}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces First principles open/closed hand predictor\relax }}{68}{figure.caption.123}\protected@file@percent }
\newlabel{fig:layers_gesture_predictor1}{{6.4}{68}{First principles open/closed hand predictor\relax }{figure.caption.123}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces First principles open/closed hand predictor\relax }}{69}{figure.caption.124}\protected@file@percent }
\newlabel{fig:layers_gesture_predictor2}{{6.5}{69}{First principles open/closed hand predictor\relax }{figure.caption.124}{}}
\citation{Australia_spiders}
\citation{markerless_ar}
\citation{ar_tabletop}
\citation{fingartips}
\citation{indian_sign_language}
\citation{combined_sign_language}
\citation{hand_classical_approach}
\citation{fingartips}
\@writefile{toc}{\contentsline {section}{2022/08/05}{70}{section*.125}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{First Semester Report Submitted}{70}{subsection*.126}\protected@file@percent }
\@writefile{brf}{\backcite{Australia_spiders}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{markerless_ar}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{ar_tabletop}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{fingartips}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{indian_sign_language}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{combined_sign_language}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{hand_classical_approach}{{70}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{fingartips}{{70}{6}{subsection*.126}}}
\citation{mediapipe_hands}
\citation{deep_cnn}
\citation{hand_pose_rgb_camera}
\citation{yolo_9000}
\citation{resnet_50}
\citation{pose_guided_cnn}
\citation{cnn_finetuning}
\citation{depth_heatmaps}
\@writefile{brf}{\backcite{mediapipe_hands}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{deep_cnn}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{hand_pose_rgb_camera}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{yolo_9000}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{resnet_50}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{pose_guided_cnn}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{cnn_finetuning}{{71}{6}{subsection*.126}}}
\@writefile{brf}{\backcite{depth_heatmaps}{{71}{6}{subsection*.126}}}
\@writefile{toc}{\contentsline {subsection}{Fixing Dying Relu Problem}{71}{subsection*.127}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Retraining of basic gesture classifier with convolutional network}{72}{subsection*.128}\protected@file@percent }
\citation{mediapipe_hands}
\@writefile{toc}{\contentsline {section}{2022/08/05}{73}{section*.129}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Brainstorming collision avoidance pipeline}{73}{subsection*.130}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Proposed Collision Avoidance Algorithm.png\relax }}{73}{figure.caption.131}\protected@file@percent }
\newlabel{fig:Proposed Collision Avoidance Algorithm}{{6.6}{73}{Proposed Collision Avoidance Algorithm.png\relax }{figure.caption.131}{}}
\@writefile{brf}{\backcite{mediapipe_hands}{{73}{6}{figure.caption.131}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Ycbcr-encoded webcam image\relax }}{74}{figure.caption.132}\protected@file@percent }
\newlabel{fig:Ycbcr_hands.png}{{6.7}{74}{Ycbcr-encoded webcam image\relax }{figure.caption.132}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Ycbcr segmentation\relax }}{74}{figure.caption.133}\protected@file@percent }
\newlabel{fig:Ycbcr_segmentation}{{6.8}{74}{Ycbcr segmentation\relax }{figure.caption.133}{}}
\@writefile{toc}{\contentsline {section}{2022/08/09}{75}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Brainstorming segmentation and more efficient algorithms}{75}{subsection*.135}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Handwritten notes brainstorming color and depth segmentation\relax }}{75}{figure.caption.136}\protected@file@percent }
\newlabel{fig:handwritten_notes_9_aug}{{6.9}{75}{Handwritten notes brainstorming color and depth segmentation\relax }{figure.caption.136}{}}
\@writefile{toc}{\contentsline {section}{2022/08/11}{76}{section*.137}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Using the Keras and Tensorflow libraries to train networks}{76}{subsection*.138}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Architecture of Keras Open Hand/Fist Classifier\relax }}{76}{figure.caption.139}\protected@file@percent }
\newlabel{fig:tensorflow_open_hand_fist_arch}{{6.10}{76}{Architecture of Keras Open Hand/Fist Classifier\relax }{figure.caption.139}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Accuracy and loss of Keras Open Hand/Fist Classifier\relax }}{77}{figure.caption.140}\protected@file@percent }
\newlabel{fig:tensorflow_open_hand_fist_accuracy}{{6.11}{77}{Accuracy and loss of Keras Open Hand/Fist Classifier\relax }{figure.caption.140}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Prediction of Keras Open Hand/Fist Classifier\relax }}{77}{figure.caption.141}\protected@file@percent }
\newlabel{fig:tensorflow_open_hand_fist_prediction1}{{6.12}{77}{Prediction of Keras Open Hand/Fist Classifier\relax }{figure.caption.141}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces Prediction of Keras Open Hand/Fist Classifier\relax }}{78}{figure.caption.142}\protected@file@percent }
\newlabel{fig:tensorflow_open_hand_fist_prediction2}{{6.13}{78}{Prediction of Keras Open Hand/Fist Classifier\relax }{figure.caption.142}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Current input to network after segmentation\relax }}{78}{figure.caption.143}\protected@file@percent }
\newlabel{fig:NN_segmented_edge_detected}{{6.14}{78}{Current input to network after segmentation\relax }{figure.caption.143}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces Segmentation using masking and the HSV color space\relax }}{79}{figure.caption.144}\protected@file@percent }
\newlabel{fig:hsv_segmentation_fast}{{6.15}{79}{Segmentation using masking and the HSV color space\relax }{figure.caption.144}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces Segmentation using masking and the Ycbcr color space\relax }}{79}{figure.caption.145}\protected@file@percent }
\newlabel{fig:ycbcr_segmentation_fast}{{6.16}{79}{Segmentation using masking and the Ycbcr color space\relax }{figure.caption.145}{}}
\@writefile{toc}{\contentsline {section}{2022/08/15}{80}{section*.146}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Discussion of current gesture recognition system inadequacies}{80}{subsection*.147}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces Current segmented input to the system\relax }}{80}{figure.caption.148}\protected@file@percent }
\newlabel{fig:network_skin_segmented_input}{{6.17}{80}{Current segmented input to the system\relax }{figure.caption.148}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces Different lighting inputs to the gesture recognition system\relax }}{81}{figure.caption.149}\protected@file@percent }
\newlabel{fig:error_segmentation_2}{{6.18}{81}{Different lighting inputs to the gesture recognition system\relax }{figure.caption.149}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.19}{\ignorespaces Current segmented input to the system\relax }}{81}{figure.caption.150}\protected@file@percent }
\newlabel{fig:error_segmentation}{{6.19}{81}{Current segmented input to the system\relax }{figure.caption.150}{}}
\@writefile{toc}{\contentsline {section}{2022/08/16}{82}{section*.151}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Construction of updated prototype implementation}{82}{subsection*.152}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.20}{\ignorespaces OpenGL and Mediapipe Pinky Tracker Prototype\relax }}{82}{figure.caption.153}\protected@file@percent }
\newlabel{fig:OpenGL_mediapipe_prototype_pinky_tracker}{{6.20}{82}{OpenGL and Mediapipe Pinky Tracker Prototype\relax }{figure.caption.153}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.21}{\ignorespaces OpenGL and Tensorflow Fist/Open Hand Prototype\relax }}{83}{figure.caption.154}\protected@file@percent }
\newlabel{fig:OpenGL_tensorflow_fist_open_hand}{{6.21}{83}{OpenGL and Tensorflow Fist/Open Hand Prototype\relax }{figure.caption.154}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.22}{\ignorespaces OpenGL and Kinect Collision Avoidance Prototype\relax }}{84}{figure.caption.155}\protected@file@percent }
\newlabel{fig:OpenGL_Kinect_collision_avoidance}{{6.22}{84}{OpenGL and Kinect Collision Avoidance Prototype\relax }{figure.caption.155}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.23}{\ignorespaces Camera controller settings\relax }}{84}{figure.caption.156}\protected@file@percent }
\newlabel{fig:camera_controller_exposure_settings}{{6.23}{84}{Camera controller settings\relax }{figure.caption.156}{}}
\@writefile{toc}{\contentsline {section}{2022/08/18}{85}{section*.157}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Gesture recognition system changes and demonstration planning}{85}{subsection*.158}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.24}{\ignorespaces Proposed camera and hardware setup for demonstration\relax }}{85}{figure.caption.159}\protected@file@percent }
\newlabel{fig:proposed_camera_setup}{{6.24}{85}{Proposed camera and hardware setup for demonstration\relax }{figure.caption.159}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.25}{\ignorespaces Proposed camera top-down view\relax }}{86}{figure.caption.160}\protected@file@percent }
\newlabel{fig:topdown_view}{{6.25}{86}{Proposed camera top-down view\relax }{figure.caption.160}{}}
\@writefile{toc}{\contentsline {section}{2022/08/19}{87}{section*.161}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hand locator}{87}{subsection*.162}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.26}{\ignorespaces Hand locator tool\relax }}{87}{figure.caption.163}\protected@file@percent }
\newlabel{fig:hand_locator_tool}{{6.26}{87}{Hand locator tool\relax }{figure.caption.163}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.27}{\ignorespaces Heatmap of hand detector\relax }}{88}{figure.caption.164}\protected@file@percent }
\newlabel{fig:heatmap_hand_detector}{{6.27}{88}{Heatmap of hand detector\relax }{figure.caption.164}{}}
\@writefile{toc}{\contentsline {section}{2022/08/23}{89}{section*.165}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hand locator changes}{89}{subsection*.166}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.28}{\ignorespaces Hand detector using mask concentration algorithm\relax }}{89}{figure.caption.167}\protected@file@percent }
\newlabel{fig:hand_detection_first_principles}{{6.28}{89}{Hand detector using mask concentration algorithm\relax }{figure.caption.167}{}}
\@writefile{toc}{\contentsline {section}{2022/08/24}{90}{section*.168}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{World Coordinate System}{90}{subsection*.169}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.29}{\ignorespaces Planning of the Kinect and virtual object coordinate system\relax }}{90}{figure.caption.170}\protected@file@percent }
\newlabel{fig:kinect_world_coords_planning}{{6.29}{90}{Planning of the Kinect and virtual object coordinate system\relax }{figure.caption.170}{}}
\@writefile{toc}{\contentsline {section}{2022/08/25}{91}{section*.171}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Virtual Object Rendering Changes}{91}{subsection*.172}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.30}{\ignorespaces Cube rendered manually using OpenCV\relax }}{91}{figure.caption.173}\protected@file@percent }
\newlabel{fig:OpenCV_cube_rendering}{{6.30}{91}{Cube rendered manually using OpenCV\relax }{figure.caption.173}{}}
\@writefile{toc}{\contentsline {section}{2022/08/30}{92}{section*.174}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Improvements to hand tracking and extracting}{92}{subsection*.175}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{2022/08/31}{93}{section*.176}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hand directions neural network}{93}{subsection*.177}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.31}{\ignorespaces Hand direction prediction\relax }}{93}{figure.caption.178}\protected@file@percent }
\newlabel{fig:hand_direction_NN_first_attempt}{{6.31}{93}{Hand direction prediction\relax }{figure.caption.178}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.32}{\ignorespaces Top-down cube grabber prototype\relax }}{94}{figure.caption.179}\protected@file@percent }
\newlabel{fig:OpenGL_tensorflow_open_hand_fist_grabber}{{6.32}{94}{Top-down cube grabber prototype\relax }{figure.caption.179}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}2022 September}{95}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/09/07}{95}{section*.180}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{First principles neural network}{95}{subsection*.181}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Output of first principles gesture classifier\relax }}{96}{figure.caption.182}\protected@file@percent }
\newlabel{fig:OpenGLCube_FP_NN_Prototype}{{7.1}{96}{Output of first principles gesture classifier\relax }{figure.caption.182}{}}
\@writefile{toc}{\contentsline {section}{2022/09/09}{97}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Kinect side-on hand tracking}{97}{subsection*.184}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Output of the side-on Kinect hand tracking\relax }}{97}{figure.caption.185}\protected@file@percent }
\newlabel{fig:kinect_side_hand_tracking}{{7.2}{97}{Output of the side-on Kinect hand tracking\relax }{figure.caption.185}{}}
\@writefile{toc}{\contentsline {section}{2022/09/12}{98}{section*.186}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Speeding up first-principles neural network}{98}{subsection*.187}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Output of the OpenGL First principles neural network gesture classifier prototype\relax }}{98}{figure.caption.188}\protected@file@percent }
\newlabel{fig:smaller_image_prediction_time}{{7.3}{98}{Output of the OpenGL First principles neural network gesture classifier prototype\relax }{figure.caption.188}{}}
\@writefile{toc}{\contentsline {section}{2022/09/22}{99}{section*.189}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Integrated prototype}{99}{subsection*.190}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Output of the integrated prototype cube rotation\relax }}{99}{figure.caption.191}\protected@file@percent }
\newlabel{fig:integrated_prototpe_1}{{7.4}{99}{Output of the integrated prototype cube rotation\relax }{figure.caption.191}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Timers showing the time taken to perform inference on an image for all three classifiers\relax }}{100}{figure.caption.192}\protected@file@percent }
\newlabel{fig:integrated_nn_speed}{{7.5}{100}{Timers showing the time taken to perform inference on an image for all three classifiers\relax }{figure.caption.192}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Accuracy of Tensorflow gesture directions classifier on a 270-item large dataset \relax }}{100}{figure.caption.193}\protected@file@percent }
\newlabel{fig:tf_directions_accuracy}{{7.6}{100}{Accuracy of Tensorflow gesture directions classifier on a 270-item large dataset \relax }{figure.caption.193}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Accuracy of Tensorflow gesture down, side, upwards facing classifier on a 420-item large dataset \relax }}{100}{figure.caption.194}\protected@file@percent }
\newlabel{fig:tf_side_down_up_accuracy}{{7.7}{100}{Accuracy of Tensorflow gesture down, side, upwards facing classifier on a 420-item large dataset \relax }{figure.caption.194}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Accuracy of Tensorflow gesture open/closed fist classifier on a 480-item large dataset \relax }}{100}{figure.caption.195}\protected@file@percent }
\newlabel{fig:tf_open_fist_accuracy}{{7.8}{100}{Accuracy of Tensorflow gesture open/closed fist classifier on a 480-item large dataset \relax }{figure.caption.195}{}}
\citation{Australia_spiders}
\citation{markerless_ar}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}2022 October}{101}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{2022/10/03}{101}{section*.196}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Final version of literature review}{101}{subsection*.197}\protected@file@percent }
\@writefile{brf}{\backcite{Australia_spiders}{{101}{8}{subsection*.197}}}
\citation{ar_tabletop}
\citation{fingartips}
\citation{indian_sign_language}
\citation{combined_sign_language}
\citation{hand_classical_approach}
\@writefile{brf}{\backcite{markerless_ar}{{102}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{ar_tabletop}{{102}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{fingartips}{{102}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{indian_sign_language}{{102}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{combined_sign_language}{{102}{8}{subsection*.197}}}
\citation{fingartips}
\citation{mediapipe_hands}
\citation{deep_cnn}
\citation{hand_pose_rgb_camera}
\citation{yolo_9000}
\citation{resnet_50}
\@writefile{brf}{\backcite{hand_classical_approach}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{fingartips}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{mediapipe_hands}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{deep_cnn}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{hand_pose_rgb_camera}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{yolo_9000}{{103}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{resnet_50}{{103}{8}{subsection*.197}}}
\citation{pose_guided_cnn}
\citation{cnn_finetuning}
\citation{depth_heatmaps}
\citation{cnn_finetuning}
\citation{depth_heatmaps}
\citation{hand_pose_occlusions}
\citation{zfnet}
\citation{deep_pose}
\@writefile{brf}{\backcite{pose_guided_cnn}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{cnn_finetuning}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{depth_heatmaps}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{cnn_finetuning}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{depth_heatmaps}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{hand_pose_occlusions}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{zfnet}{{104}{8}{subsection*.197}}}
\@writefile{brf}{\backcite{deep_pose}{{105}{8}{subsection*.197}}}
\citation{Australia_spiders}
\citation{markerless_ar}
\citation{ar_tabletop}
\@writefile{toc}{\contentsline {section}{2022/10/10}{107}{section*.198}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Revised Final version of literature review}{107}{subsection*.199}\protected@file@percent }
\@writefile{brf}{\backcite{Australia_spiders}{{107}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{markerless_ar}{{107}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{ar_tabletop}{{107}{8}{subsection*.199}}}
\citation{fingartips}
\citation{ransacpointcloud}
\citation{snaptoreality}
\citation{snaptoreality}
\citation{liu2019planercnn}
\citation{yang2010plane}
\citation{indian_sign_language}
\citation{combined_sign_language}
\@writefile{brf}{\backcite{fingartips}{{108}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{ransacpointcloud}{{108}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{snaptoreality}{{108}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{snaptoreality}{{108}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{liu2019planercnn}{{108}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{yang2010plane}{{108}{8}{subsection*.199}}}
\citation{hand_classical_approach}
\citation{fingartips}
\citation{mediapipe_hands}
\citation{deep_cnn}
\citation{hand_pose_rgb_camera}
\citation{yolo_9000}
\citation{resnet_50}
\@writefile{brf}{\backcite{indian_sign_language}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{combined_sign_language}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{hand_classical_approach}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{fingartips}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{mediapipe_hands}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{deep_cnn}{{109}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{hand_pose_rgb_camera}{{109}{8}{subsection*.199}}}
\citation{pose_guided_cnn}
\citation{cnn_finetuning}
\citation{depth_heatmaps}
\citation{cnn_finetuning}
\citation{depth_heatmaps}
\citation{hand_pose_occlusions}
\citation{zfnet}
\@writefile{brf}{\backcite{yolo_9000}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{resnet_50}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{pose_guided_cnn}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{cnn_finetuning}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{depth_heatmaps}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{cnn_finetuning}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{depth_heatmaps}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{hand_pose_occlusions}{{110}{8}{subsection*.199}}}
\@writefile{brf}{\backcite{zfnet}{{110}{8}{subsection*.199}}}
\citation{deep_pose}
\@writefile{brf}{\backcite{deep_pose}{{111}{8}{subsection*.199}}}
\@writefile{toc}{\contentsline {subsection}{Final implementation progress}{112}{subsection*.200}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendices}{114}{section*.201}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Acronyms}{114}{section*.202}\protected@file@percent }
\newacro{AI}[\AC@hyperlink{AI}{AI}]{Artificial Intelligence}
\newacro{ANN}[\AC@hyperlink{ANN}{ANN}]{Artificial Neural Network}
\newacro{BIC}[\AC@hyperlink{BIC}{BIC}]{Bayesian Information Criterion}
\newacro{CRF}[\AC@hyperlink{CRF}{CRF}]{Conditional Random Field}
\newacro{CRFs}[\AC@hyperlink{CRFs}{CRFs}]{Conditional Random Fields}
\newacro{CVPR}[\AC@hyperlink{CVPR}{CVPR}]{Computer Vision and Pattern Recognition}
\newacro{dB}[\AC@hyperlink{dB}{dB}]{decibel}
\newacro{DBN}[\AC@hyperlink{DBN}{DBN}]{dynamic Bayesian network}
\newacro{EBIT}[\AC@hyperlink{EBIT}{EBIT}]{Faculty of Engineering, Built Environment and Information Technology}
\newacro{ECCV}[\AC@hyperlink{ECCV}{ECCV}]{European Conference on Computer Vision}
\newacro{EECE}[\AC@hyperlink{EECE}{EECE}]{Department of Electrical, Electronic and Computer Engineering}
\newacro{EKF}[\AC@hyperlink{EKF}{EKF}]{Extended Kalman Filter}
\newacro{EM}[\AC@hyperlink{EM}{EM}]{Expectation Maximisation}
\newacro{FFNN}[\AC@hyperlink{FFNN}{FFNN}]{feed-forward neural network}
\newacro{FFT}[\AC@hyperlink{FFT}{FFT}]{Fast Fourier Transform}
\newacro{FOV}[\AC@hyperlink{FOV}{FOV}]{Field Of View}
\newacro{fps}[\AC@hyperlink{fps}{fps}]{Frames per second}
\newacro{FPU}[\AC@hyperlink{FPU}{FPU}]{Floating Point Unit}
\newacro{FSM}[\AC@hyperlink{FSM}{FSM}]{Finite State Machine}
\newacro{GA}[\AC@hyperlink{GA}{GA}]{Genetic Algorithm}
\newacro{GAs}[\AC@hyperlink{GAs}{GAs}]{Genetic Algorithms}
\newacro{GD}[\AC@hyperlink{GD}{GD}]{Gradient Descent}
\newacro{GMs}[\AC@hyperlink{GMs}{GMs}]{graphical models}
\newacro{GNU}[\AC@hyperlink{GNU}{GNU}]{Recursive Acronym: GNU's Not Unix}
\newacro{GP}[\AC@hyperlink{GP}{GP}]{Gaussian Process}
\newacro{GPs}[\AC@hyperlink{GPs}{GPs}]{Gaussian Processes}
\newacro{GPL}[\AC@hyperlink{GPL}{GPL}]{General Public Licence}
\newacro{GUI}[\AC@hyperlink{GUI}{GUI}]{Graphical Users Interface}
\newacro{HMM}[\AC@hyperlink{HMM}{HMM}]{Hidden Markov Model}
\newacro{HMMs}[\AC@hyperlink{HMMs}{HMMs}]{Hidden Markov Models}
\newacro{HVS}[\AC@hyperlink{HVS}{HVS}]{human visual system}
\newacro{ICA}[\AC@hyperlink{ICA}{ICA}]{Independent Component Analysis}
\newacro{ICCV}[\AC@hyperlink{ICCV}{ICCV}]{International Conference on Computer Vision}
\newacro{ICRA}[\AC@hyperlink{ICRA}{ICRA}]{International Conference on Robotics and Automation}
\newacro{IEEE}[\AC@hyperlink{IEEE}{IEEE}]{Institute of Electrical and Electronics Engineers}
\newacro{IROS}[\AC@hyperlink{IROS}{IROS}]{Intelligent Robots and Systems}
\newacro{LUT}[\AC@hyperlink{LUT}{LUT}]{lookup table}
\newacro{MC}[\AC@hyperlink{MC}{MC}]{Monte Carlo methods}
\newacro{MDP}[\AC@hyperlink{MDP}{MDP}]{Markov Decision Process}
\newacro{MDS}[\AC@hyperlink{MDS}{MDS}]{multi-dimensional scaling}
\newacro{MIT}[\AC@hyperlink{MIT}{MIT}]{Massachusetts Institute of Technology}
\newacro{ML}[\AC@hyperlink{ML}{ML}]{machine learning}
\newacro{MLE}[\AC@hyperlink{MLE}{MLE}]{maximum likelihood estimation}
\newacro{PCA}[\AC@hyperlink{PCA}{PCA}]{Principle Component Analysis}
\newacro{POMDP}[\AC@hyperlink{POMDP}{POMDP}]{Partially Observable Markov Decision Process}
\newacro{PSO}[\AC@hyperlink{PSO}{PSO}]{Particle Swarm Optimisation}
\newacro{PV}[\AC@hyperlink{PV}{PV}]{Pixel Value}
\newacro{RANSAC}[\AC@hyperlink{RANSAC}{RANSAC}]{Random Sample Consensus}
\newacro{RGB}[\AC@hyperlink{RGB}{RGB}]{Red Green Blue}
\newacro{RNG}[\AC@hyperlink{RNG}{RNG}]{random number generator}
\newacro{RNGs}[\AC@hyperlink{RNGs}{RNGs}]{random number generators}
\newacro{ROI}[\AC@hyperlink{ROI}{ROI}]{Region of Interest}
\newacro{RPROP}[\AC@hyperlink{RPROP}{RPROP}]{Resilient Propagation}
\newacro{RSS}[\AC@hyperlink{RSS}{RSS}]{residual sums of squares}
\newacro{SA}[\AC@hyperlink{SA}{SA}]{Simulated Annealing}
\newacro{SLAM}[\AC@hyperlink{SLAM}{SLAM}]{Simultaneous localization and mapping}
\newacro{SSE}[\AC@hyperlink{SSE}{SSE}]{Sum Squared Error}
\newacro{SVD}[\AC@hyperlink{SVD}{SVD}]{Singular Value Decomposition}
\newacro{SVM}[\AC@hyperlink{SVM}{SVM}]{Support Vector Machine}
\newacro{SVMs}[\AC@hyperlink{SVMs}{SVMs}]{Support Vector Machines}
\newacro{UP}[\AC@hyperlink{UP}{UP}]{University of Pretoria}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Email dated Friday 17 June 2022 between Mr. Grobler and Mr. Williams\relax }}{115}{figure.caption.203}\protected@file@percent }
\newlabel{fig:grobler_email}{{1}{115}{Email dated Friday 17 June 2022 between Mr. Grobler and Mr. Williams\relax }{figure.caption.203}{}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{Du2Net}{1}
\bibcite{hand_ar_shen}{2}
\bibcite{canterbury_hand_ar}{3}
\bibcite{kim_leap_ar}{4}
\bibcite{lee_hand_ar}{5}
\bibcite{jones_skin_color}{6}
\bibcite{drones_hololens}{7}
\bibcite{mediapipe_hands}{8}
\bibcite{deep_pose}{9}
\bibcite{Australia_spiders}{10}
\bibcite{markerless_ar}{11}
\bibcite{ar_tabletop}{12}
\@writefile{toc}{\contentsline {chapter}{References}{116}{figure.caption.203}\protected@file@percent }
\bibcite{fingartips}{13}
\bibcite{indian_sign_language}{14}
\bibcite{combined_sign_language}{15}
\bibcite{hand_classical_approach}{16}
\bibcite{deep_cnn}{17}
\bibcite{hand_pose_rgb_camera}{18}
\bibcite{yolo_9000}{19}
\bibcite{resnet_50}{20}
\bibcite{pose_guided_cnn}{21}
\bibcite{cnn_finetuning}{22}
\bibcite{depth_heatmaps}{23}
\bibcite{hand_pose_occlusions}{24}
\bibcite{zfnet}{25}
\bibcite{ransacpointcloud}{26}
\bibcite{snaptoreality}{27}
\bibcite{liu2019planercnn}{28}
\bibcite{yang2010plane}{29}
\newlabel{LastPage}{{}{118}{}{page.118}{}}
\xdef\lastpage@lastpage{118}
\xdef\lastpage@lastpageHy{118}
\gdef \@abspage@last{118}
